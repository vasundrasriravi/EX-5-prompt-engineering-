# EXP 5: Comparative Analysis of Naïve Prompting versus Basic Prompting Using ChatGPT Across Various Test Scenarios
# Aim: 
To test how ChatGPT responds to naïve prompts (broad or unstructured) versus basic prompts (clearer and more refined) across multiple scenarios, analyzing the quality, accuracy, and depth of the generated responses.
# Algorithm: 
### Design Prompt Pairs:
Create two prompts for each scenario—one naïve and one basic.
Example for creative writing:
-> Naïve: “Tell me a story.”
-> Basic: “Write a bedtime story about a shy rabbit who finds courage to talk to other animals.”

### Run Both Prompts on ChatGPT:
-> Input each naïve prompt and record the response.
-> Input the corresponding basic prompt and record the response.Repeat for all scenarios.

### Analyze the Responses:
Compare outputs based on:
* Quality of content
* Accuracy of information (if factual)
* Creativity or detail
* Relevance and clarity
Note differences in performance.

### Document Findings:
Prepare a comparison table showing both responses and observations on which prompt type was more effective.

# Prompt Pairs for Test Scenarios
![Screenshot 2025-05-21 111828](https://github.com/user-attachments/assets/0611f6f9-5258-480f-ad1b-57facca4eb4f)

# Output
![Screenshot 2025-05-21 113143](https://github.com/user-attachments/assets/b0056bfd-487f-4873-ade0-589d7806139b)

# Result: 
The prompt for the above said problem executed successfully.
